import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim

import matplotlib.pyplot as plt
import numpy as np


# load dataset
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
#                                         download=True, transform=transform)
# trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
#                                           shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=1,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.batch1 = torch.nn.BatchNorm2d(6)
        self.relu1 = nn.ReLU(True)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.batch2 = torch.nn.BatchNorm2d(16)
        self.relu2 = nn.ReLU(True)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc1_relu = nn.ReLU(True)
        self.fc2 = nn.Linear(120, 84)
        self.fc2_relu = nn.ReLU(True)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool1(self.relu1(self.batch1(self.conv1(x))))
        x = self.pool2(self.relu2(self.batch2(self.conv2(x))))
        x = x.view(-1, 16 * 5 * 5)
        x = self.fc1_relu(self.fc1(x))
        x = self.fc2_relu(self.fc2(x))
        x = self.fc3(x)
        return x



class Feature_Extractor(nn.Module):
    def __init__(self):
        super(Feature_Extractor, self).__init__()
        model = torch.load('./CIFAR10_cnn_model.pk')

        #get all the convolution layers
        self.conv_feature = nn.Sequential(*list(model.children())[:8])

        #remove the last fully connected layer
        self.fc_feature = nn.Sequential(*list(model.children())[8:-2])
        print('###########  conv feature  ###############')
        print(self.conv_feature)
        print('################ fully connected layer #########################')
        print(self.fc_feature)
        print('#######################################################')

    def forward(self, x):
        #Extract the feature generated by the last fully CONVOLUTION layer
        conv_feat = self.conv_feature(x)
        # print(conv_feat)
        #flatten the feature
        conv_feat = conv_feat.view(-1, 400)

        #Extract the feature generated by the last fully CONNECTED layer
        fc_feat = self.fc_feature(conv_feat)

        #In the old model, the return value is the classification prediciton
        #In here, the return value is the future
        return fc_feat


model = torch.load('./CIFAR10_cnn_model.pk')
# print('model:' model)


#initialize the new model to extract features
feature_extractor = Feature_Extractor()

#set the model into evaluation mode
feature_extractor.eval()

#to store the features for the testing data
img_feat = []

#to store the labels for the testing data
img_label = []

img_cnt = 0
for data, target in testloader:
    # print(data.size())
    # print(target)

    #send the data to the feature extractor and get the output
    output = feature_extractor(data)
    # print(output.size())

    #only extract features for the random selected 1000 images
    #you can change this number
    img_cnt = img_cnt + 1
    if img_cnt >= 1000:
        break

    label = target.cpu().data.numpy()
    # print(label)
    feature = output.cpu().data.numpy()
    # print(feature)

    #normalize feature into 0 and 1
    #why we need to normalize the feature?
    feature = (feature - np.amin(feature))/(np.amax(feature) - np.amin(feature))

    #append into a list
    img_label.append(label)
    img_feat.append(feature)

##############################################################
# write the label and data into separate fiels
##############################################################

with open('./img_data.txt', 'w') as f:
    for data in img_feat:
        # print(data[0,:].shape)
        f.write(" ".join(map(str, data[0,:])))
        f.write("\n")

f_label = open('./label_data.txt', "w")
for data in img_label:
    # print(data.shape)
    np.savetxt(f_label, data, newline='\n')
