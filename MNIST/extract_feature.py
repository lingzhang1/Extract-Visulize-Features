import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from sklearn.datasets import fetch_mldata
import numpy as np


#####################################################################################
# This is the code for the original network
# later we will extract the feature of the fc1 and fc2
#####################################################################################
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.relu1 = nn.ReLU(True)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.relu2 = nn.ReLU(True)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.relu_fc1 = nn.ReLU(True)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, img):

        conv1_feat = self.conv1(img)
        conv1_feat = self.pool1(conv1_feat)
        conv1_feat = self.relu1(conv1_feat)
        conv2_feat = self.conv2(conv1_feat)
        conv2_feat = self.pool2(conv2_feat)
        conv2_feat = self.relu2(conv2_feat)


        conv2_feat = conv2_feat.view(-1, 320)
        fc1_feat = self.fc1(conv2_feat)
        fc1_feat = self.relu_fc1(fc1_feat)
        fc1_feat = F.dropout(fc1_feat, training=self.training)
        fc2_feat = self.fc2(fc1_feat)
        return F.log_softmax(fc2_feat, dim=1)


#######################################################################################
#extract the fc1 features with the trained model
# 1. load the pre-trained model
# 2. remove the last 2 layers of the original model
# 3. construct nwe forward function with the new layer
#######################################################################################
class Feature_Extractor(nn.Module):
    def __init__(self):
        super(Feature_Extractor, self).__init__()
        model = torch.load('./mnist_cnn_model.pk')

        #get all the convolution layers
        self.conv_feature = nn.Sequential(*list(model.children())[:7])

        #remove the last fully connected layer
        self.fc_feature = nn.Sequential(*list(model.children())[7:-2])
        print('###########  conv feature  ###############')
        print(self.conv_feature)
        print('################ fully connected layer #########################')
        print(self.fc_feature)
        print('#######################################################')

    def forward(self, x):
        #Extract the feature generated by the last fully CONVOLUTION layer
        conv_feat = self.conv_feature(x)

        #flatten the feature
        conv_feat = conv_feat.view(-1, 320)

        #Extract the feature generated by the last fully CONNECTED layer
        fc_feat = self.fc_feature(conv_feat)

        #In the old model, the return value is the classification prediciton
        #In here, the return value is the future
        return fc_feat




def main():
    # Training settings
    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')
    parser.add_argument('--batch-size', type=int, default=1, metavar='N',
                        help='input batch size for training (default: 1000)')
    parser.add_argument('--test-batch-size', type=int, default=1, metavar='N',
                        help='input batch size for testing (default: 1000)')
    parser.add_argument('--epochs', type=int, default=1, metavar='N',
                        help='number of epochs to train (default: 10)')
    parser.add_argument('--no-cuda', action='store_true', default=False,
                        help='disables CUDA training')
    parser.add_argument('--seed', type=int, default=1, metavar='S',
                        help='random seed (default: 1)')


    args = parser.parse_args()
    use_cuda = not args.no_cuda and torch.cuda.is_available()

    torch.manual_seed(args.seed)

    device = torch.device("cuda" if use_cuda else "cpu")

    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

    test_loader = torch.utils.data.DataLoader(
        datasets.MNIST('../data', train=False, transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
                       ])),
        batch_size=args.test_batch_size, shuffle=True, **kwargs)


    ##############################################################################
    # load the pre-trained model
    ##############################################################################
    model = torch.load('./mnist_cnn_model.pk')
    print(model)


    #initialize the new model to extract features
    feature_extractor = Feature_Extractor().to(device)
    print('-----------------------------------------')
    # print(feature_extractor)


    #set the model into evaluation mode
    feature_extractor.eval()

    #to store the features for the testing data
    img_feat = []

    #to store the labels for the testing data
    img_label = []

    img_cnt = 0
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        # print(data.size())
        # print(target)

        #send the data to the feature extractor and get the output
        output = feature_extractor(data)
        # print(output.size())

        #only extract features for the random selected 1000 images
        #you can change this number
        img_cnt = img_cnt + 1
        if img_cnt >= 1000:
            break

        label = target.cpu().data.numpy()
        # print(label)
        feature = output.cpu().data.numpy()
        # print(feature)

        #normalize feature into 0 and 1
        #why we need to normalize the feature?
        feature = (feature - np.amin(feature))/(np.amax(feature) - np.amin(feature))

        #append into a list
        img_label.append(label)
        img_feat.append(feature)

    ##############################################################
    # write the label and data into separate fiels
    ##############################################################

    with open('./img_data.txt', 'w') as f:
        for data in img_feat:
            # print(data[0,:].shape)
            f.write(" ".join(map(str, data[0,:])))
            f.write("\n")

    f_label = open('./label_data.txt', "w")
    for data in img_label:
        # print(data.shape)
        np.savetxt(f_label, data, newline='\n')

if __name__ == '__main__':
    main()
